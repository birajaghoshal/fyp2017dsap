{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib as mpl  \n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "\n",
    "import keras as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from scipy.ndimage.morphology import binary_fill_holes, binary_closing, binary_dilation  \n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_annotations = pd.read_table('subject_annotations.txt')\n",
    "sample_annotations = pd.read_table('sample_annotations.txt')\n",
    "\n",
    "sample_id_list = sample_annotations['SAMPID']\n",
    "sample_id_dict = {}\n",
    "\n",
    "# Create dictionary of slide names and corresponding index in sample annotations txt\n",
    "for i in range(0, len(sample_id_list)):\n",
    "    sample_id = sample_id_list[i]\n",
    "    sample_id_shortened = sample_id[0:sample_id.rfind(\"-\", 0, sample_id.rfind(\"-\"))]\n",
    "    sample_id_dict[sample_id_shortened] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tile_img_matrix(data_type, slide_type):\n",
    "    '''\n",
    "    Iterates through tiles and returns:\n",
    "    1. NdArray of image matrices \n",
    "    2. Array of scores corresponding to tile image\n",
    "    '''\n",
    "    read_slides_path = \"data/\" + data_type + \"/\" + slide_type + \"s/\"\n",
    "    tiles = glob(read_slides_path + \"*.png\")    \n",
    "    \n",
    "    img_matrix_array = []\n",
    "    scores_array = np.array([])\n",
    "    \n",
    "    for tile in tiles:\n",
    "        \n",
    "        # append image matrix\n",
    "        tile_data = scipy.misc.imread(tile)\n",
    "        img_matrix_array.append(tile_data)\n",
    "        \n",
    "        # read slide name from tile [slide_name]_[slide_index].png score value\n",
    "        slide_name = tile[tile.rfind('/')+1:tile.rfind('_')]\n",
    "        row_index = sample_id_dict[slide_name]\n",
    "        # get Intragenic Rate: The fraction of reads that map within genes (within introns or exons)\n",
    "        SMNTRART = sample_annotations.iloc[[row_index]]['SMNTRART'].values[0]\n",
    "        row = np.array([SMNTRART])\n",
    "        scores_array = np.concatenate((scores_array, row))\n",
    "    \n",
    "    return img_matrix_array, scores_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate image matrices for each slide and data type\n",
    "liver_test_data, liver_test_labels = generate_tile_img_matrix(\"validation\", \"liver\")\n",
    "lung_test_data, lung_test_labels = generate_tile_img_matrix(\"validation\", \"lung\")\n",
    "liver_train_data, liver_train_labels = generate_tile_img_matrix(\"train\", \"liver\")\n",
    "lung_train_data, lung_train_labels = generate_tile_img_matrix(\"train\", \"lung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 128, 128, 3)\n",
      "(541,)\n",
      "(837, 128, 128, 3)\n",
      "(837,)\n",
      "(2221, 128, 128, 3)\n",
      "(2221,)\n",
      "(3133, 128, 128, 3)\n",
      "(3133,)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "liver_test_data = np.asarray(liver_test_data)\n",
    "lung_test_data = np.asarray(lung_test_data)\n",
    "print(liver_test_data.shape)\n",
    "print(liver_test_labels.shape)\n",
    "print(lung_test_data.shape)\n",
    "print(lung_test_labels.shape)\n",
    "\n",
    "liver_train_data = np.asarray(liver_train_data)\n",
    "lung_train_data = np.asarray(lung_train_data)\n",
    "print(liver_train_data.shape)\n",
    "print(liver_train_labels.shape)\n",
    "print(lung_train_data.shape)\n",
    "print(lung_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train data\n",
    "x_train = np.concatenate((lung_train_data, liver_train_data))\n",
    "y_train = np.concatenate((lung_train_labels, liver_train_labels))\n",
    "\n",
    "for x_batch, y_batch in train_datagen.flow(x_train, y_train, batch_size=x_train.shape[0]):\n",
    "    x_train = x_batch\n",
    "    y_train = y_batch\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test data\n",
    "x_test = np.concatenate((lung_test_data, liver_test_data))\n",
    "y_test = np.concatenate((lung_test_labels, liver_test_labels))\n",
    "\n",
    "for x_batch, y_batch in train_datagen.flow(x_test, y_test, batch_size=x_test.shape[0]):\n",
    "    x_test = x_batch\n",
    "    y_test = y_batch\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5354/5354 [==============================] - 6s - loss: 0.0099     \n",
      "Epoch 2/10\n",
      "5354/5354 [==============================] - 4s - loss: 7.6198e-04     \n",
      "Epoch 3/10\n",
      "1360/5354 [======>.......................] - ETA: 3s - loss: 2.5157e-04"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model \n",
    "\n",
    "clf = KerasRegressor(build_fn=base_model, nb_epoch=1000, batch_size=16, verbose=1)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_prediction = clf.predict(x_train)\n",
    "plt.scatter(in_sample_prediction, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sample_prediction = clf.predict(x_test)\n",
    "plt.scatter(out_sample_prediction, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_1 = mean_squared_error(y_train, in_sample_prediction)\n",
    "mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_2 = mean_squared_error(y_test, out_sample_prediction)\n",
    "mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python3 Tensorflow Keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
